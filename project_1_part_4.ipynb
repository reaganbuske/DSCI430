{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 Part 4 - Creating a master parcel database\n",
    "\n",
    "In this part of the project, we will use Python to read, process, and double all of the parcel data into a database.  Note that this is not our only alternative, and in Project 1 Part 4 b, we will look at another alternative, that is reading all the of original, raw files into their own database table, then using SQL to join/link/aggregate the tables.\n",
    "\n",
    "## Chunking Files in Pandas – Part 1 (20 Points)\n",
    "\n",
    "In this part of the project, you will use `Panda`’s to process the data from the MinneMUDAC 2016 competition Dive into Water Data.  The data can be found at the [MinneMUDAC site](http://minneanalytics.org/minnemudac/data/).  You should document your work in a Jupyter notebook, which will be used to submit your solution.  **For the rest of the parts of this project, we will limit ourselves to the years 2004-2014.**\n",
    "\n",
    "1. Remind me why we want to skip 2003."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import the common columns list and translation dictionaries from the `.py` file you created in the last part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use glob and a list comprehension to get a list of file names for the years 2004-2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the first chunk of the first file to prototype an expression that <br>\n",
    "    a. Selects the common columns <br>\n",
    "    b. Fixes any issues with the column names <br>\n",
    "    c. Changes columns to the correct types (if necessary).  More information about the columns can be found [here](ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metrogis/plan_regonal_prcls_open/metadata/metadata.html). It is **imperative** that you keep the lat and long columns as strings. <br>\n",
    "    d. Use the translation dictionaries from the last part to add three new columns to the chunk: lake code, lake name, parcel distance to the lake.\n",
    "    e. Filters to only properties that are within 1600 m (~1 mile) of the closest lake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Now convert your expression from the last problem to a function and test that this function works on the first few chunks of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We need to make a unique primary key for each row in the combined parcel file.<br>\n",
    "    a. There is a column that appears to be a unique parcel id.  Double check that this is a true primary key for each individual file. (To do this you need to verify that the number of unique values is the same as the number of rows for each of the parcel files.  **Hint:** For each file, use of the accumulator pattern with two accumualtors (one number and one data frame). <br>\n",
    "    b. Explain why this column will not work as a primary key if we want to combine all years in one database. <br>\n",
    "    c. Suppose we make a new column that consist of `str(year) + '-' + PID`.  Explain why this should make a proper primary key for the combined data. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make a function to add the key suggested in the last problem (`str(year) + '-' + PID`) to a given chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: If you are clever, you can do parts 8 in one double loop, which will save you from having to read the parcel files twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. It is probably worth our time to test that our new key column is truely unique. (If not, we might be wasting out time loading the data into a database, only to have process fail hours in.) Test that the new column works by <br>\n",
    "    a. Iterating over all the files.<br>\n",
    "    b. Using an accumulator to count total number of rows across all parcel files. <br>\n",
    "    c. Using an accumulator to accumulate a set of all unique values of our new key. <br>\n",
    "    d. Verifying that we have as many total rows as unique keys.\n",
    "    a. Selecting just this column. <br>\n",
    "    b. Dumping this column into a temporary database <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. If the last step succeeded, you can proceed to make a master parcel data database.  If not, you will need to figure out another primary key, probably an `id` column similar to the example in the lectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
